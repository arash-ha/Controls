{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-Zy5R377k8C"
   },
   "source": [
    "# Main Script\n",
    "\n",
    "In this project, bounding boxes are connected to multiple frames using the Hungarian Algorithm!\n",
    "\n",
    "This work is done based on 4 aspects of the **multi-object tracker**:\n",
    "\n",
    "*   Using YOLO and launch an object detection algorithm\n",
    "*   Using The Hungarian Algorithm and connecting the boxes\n",
    "*   Improving the algorithm to prevent false positives and false negatives\n",
    "*   Using Kalman Filters to help predict the future position of a bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbG8vs9u8OOg"
   },
   "source": [
    "This is a part included to link the Google Colab file (.ipynb) to your Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20883,
     "status": "ok",
     "timestamp": 1611337088284,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "ZPW9hbcuYxqO",
    "outputId": "c7d18c72-b9fd-4cc2-8b90-c5cc62c27e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Association  Detection\tMain  movie.mp4  README.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Tracking\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcNCkytu3ykt"
   },
   "source": [
    "# 1 - Detection\n",
    "\n",
    "For Tracking, the first step is detection. The tracking heavily relies on the detection. In this project, [YOLO algorithm](https://pjreddie.com/darknet/yolo/) was selected because of accuracy and speed.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1446/1*YpNE9OQeshABhBgjyEXlLA.png\" width=\"500\">\n",
    "\n",
    "Eventually, our aim is to have a bounding box detection like the below picture.\n",
    "\n",
    "<img src=\"https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UStSXSC3RKue"
   },
   "source": [
    "## Import Libraries and Test Images\n",
    "\n",
    "In this project, the frame per second of video is sixty fps but we use every seven image in fps. In other words, Instead of working at **60 FPS** (recording frame rate), the algorithm is working at 60/7 or about **9 frame per second**.<p>\n",
    "**The reason behind this ?**<p>\n",
    "YOLO is very fast, it can work at 60 FPS. For tracking purpose, 60 fps is a bit challenging. Because of that, let's not have 99% IOU every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21504,
     "status": "ok",
     "timestamp": 1611337088912,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "9n24pesxqdTP"
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 22281,
     "status": "ok",
     "timestamp": 1611337089696,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "cJ6bw_4Rqh3T"
   },
   "outputs": [],
   "source": [
    "### Load the Images\n",
    "dataset_images = pickle.load(open('Main/Images/images_tracking.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 22276,
     "status": "ok",
     "timestamp": 1611337089697,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "duVgFEYHfRsM"
   },
   "outputs": [],
   "source": [
    "def visualize_images(input_images):\n",
    "    fig=plt.figure(figsize=(100,100))\n",
    "\n",
    "    for i in range(len(input_images)):\n",
    "        fig.add_subplot(1, len(input_images), i+1)\n",
    "        plt.imshow(input_images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "output_embedded_package_id": "15QPDRh77iJ8vz5Q8RfmcEx5eI1LKZhSx"
    },
    "executionInfo": {
     "elapsed": 27555,
     "status": "ok",
     "timestamp": 1611337094995,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "ref3X-llqt4o",
    "outputId": "5bb8d3bc-3a36-45a5-ccf2-309eba77bfce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_images(dataset_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39164,
     "status": "ok",
     "timestamp": 1611337106619,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "S2QETWZhM3j8",
    "outputId": "3de2357f-4661-43bb-9e66-6f31b0c186d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "[[[474, 207, 295, 158], [147, 213, 74, 51], [265, 214, 65, 53], [112, 212, 12, 22], [346, 203, 42, 43], [216, 214, 38, 31], [149, 215, 73, 50], [265, 221, 65, 43]], [[469, 208, 302, 155], [143, 213, 73, 51], [259, 214, 68, 53], [103, 213, 13, 22], [253, 216, 16, 12], [339, 202, 43, 45], [145, 210, 73, 49], [212, 216, 40, 30], [262, 222, 63, 43]], [[471, 206, 296, 155], [148, 212, 72, 51], [264, 211, 69, 56], [344, 202, 44, 45], [654, 205, 18, 24], [153, 209, 68, 52], [217, 213, 39, 30], [265, 220, 65, 43]], [[471, 214, 293, 146], [153, 214, 68, 51], [269, 213, 64, 57], [102, 212, 13, 25], [681, 204, 21, 39], [218, 217, 42, 29], [342, 209, 51, 42], [425, 216, 11, 25], [711, 213, 19, 43], [157, 218, 64, 46], [269, 222, 63, 44]], [[477, 211, 283, 143], [158, 213, 72, 52], [273, 215, 70, 50], [352, 204, 43, 41], [395, 213, 9, 18], [425, 211, 9, 19], [446, 211, 11, 20], [225, 213, 41, 31], [721, 202, 24, 57], [162, 216, 62, 48], [275, 220, 65, 46], [752, 204, 15, 73]], [[466, 208, 265, 144], [148, 214, 74, 49], [91, 207, 15, 28], [339, 202, 45, 44], [388, 210, 9, 23], [424, 209, 9, 25], [447, 210, 8, 19], [216, 212, 44, 31], [266, 211, 63, 41], [742, 189, 24, 89], [151, 217, 71, 44]], [[461, 204, 255, 147], [146, 206, 72, 54], [266, 205, 65, 55], [80, 206, 15, 24], [215, 209, 44, 31], [323, 211, 16, 18], [339, 202, 46, 44], [390, 210, 8, 23], [425, 209, 8, 20], [147, 208, 74, 51], [263, 210, 66, 43]], [[456, 222, 257, 134], [150, 215, 74, 50], [268, 213, 66, 55], [82, 208, 14, 26], [326, 215, 13, 16], [220, 215, 41, 30], [345, 208, 41, 44], [395, 219, 8, 21], [444, 220, 8, 22], [464, 221, 8, 18], [642, 218, 16, 24], [154, 216, 69, 48], [268, 222, 65, 44]], [[462, 219, 258, 134], [167, 219, 71, 54], [281, 219, 64, 56], [92, 219, 18, 26], [340, 222, 17, 17], [355, 213, 42, 42], [410, 222, 9, 24], [449, 222, 8, 18], [462, 221, 9, 22], [484, 222, 10, 19], [670, 218, 22, 36], [167, 218, 73, 55], [236, 223, 38, 30], [283, 222, 64, 43]]]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Tracking/Main\")\n",
    "### Run obstacle detection for the images\n",
    "from yolo_for_tracking import *\n",
    "\n",
    "result_images = [] # Empty list for output images\n",
    "result_boxes = [] # Empty list for output boxes\n",
    "\n",
    "# Initiliaze an object detector\n",
    "detector = YOLO()\n",
    "\n",
    "images = copy.deepcopy(dataset_images)\n",
    "\n",
    "# For every image, run a detector using the inference() function\n",
    "for img in images:\n",
    "    result, boxes = detector.inference(img)\n",
    "    result_images.append(result)\n",
    "    result_boxes.append(boxes)\n",
    "\n",
    "print(result_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "output_embedded_package_id": "1h1fmw_q_kIiKiWj2MLPvrs63-nzb1Ykw"
    },
    "executionInfo": {
     "elapsed": 44612,
     "status": "ok",
     "timestamp": 1611337112080,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "bHvtTDrEVr_7",
    "outputId": "89db408e-9b28-40b4-eb7e-2c00e630304b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results and the detected boxes\n",
    "visualize_images(result_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUIbq5XkXGaY"
   },
   "source": [
    "## For each Obstacle, specific Color is assigned\n",
    "**Last Step!** <p>\n",
    "All cars in one color is useless! Because of that, the code will be modified <p>\n",
    "Each detected obstacle has:\n",
    "* an id\n",
    "* a current bounding box\n",
    "* a previous bounding box<p>_\n",
    "\n",
    "**In the end, we will draw a bounding box based on the id.** <p>\n",
    "If the id changes, the color will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 44609,
     "status": "ok",
     "timestamp": 1611337112081,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "a99w3HIF1MLL"
   },
   "outputs": [],
   "source": [
    "class Obstacle():\n",
    "    def __init__(self, idx, box):\n",
    "        \"\"\"\n",
    "        Init function - The obstacle must have an id and a box.\n",
    "        \"\"\"\n",
    "        self.idx = idx\n",
    "        self.box = box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 44607,
     "status": "ok",
     "timestamp": 1611337112082,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "-ly04QA_gOMJ"
   },
   "outputs": [],
   "source": [
    "def id_to_color(idx):\n",
    "    # Random function to convert an id to a color\n",
    "    blue = idx * 5 % 256\n",
    "    green = idx * 36 % 256\n",
    "    red = idx * 23 % 256\n",
    "    return (red, green, blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 44603,
     "status": "ok",
     "timestamp": 1611337112083,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "yWacVf_5gShC"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # assigning an id and draw a rectangle based on each id\n",
    "    \n",
    "    idx = 0\n",
    "    obstacles = []\n",
    "    result_images_2 = copy.deepcopy(dataset_images) # Copy the image without modifying the dataset\n",
    "    for j, boxes in enumerate(result_boxes): # loop through all images\n",
    "        for i, box in enumerate(boxes): # loop through all boxes\n",
    "            obs = Obstacle(idx, box)\n",
    "            left, top, width, height = box\n",
    "            right = left + width\n",
    "            bottom = top + height\n",
    "            cv2.rectangle(result_images_2[j], (left, top), (right, bottom), id_to_color(idx+i), thickness=10)\n",
    "            idx += 1\n",
    "            obstacles.append(obs)\n",
    "    return result_images_2\n",
    "\n",
    "result_images_2 = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "output_embedded_package_id": "1tW0VW7NQHFt4efP3PL3eWsZkzU7eJY_Z"
    },
    "executionInfo": {
     "elapsed": 47239,
     "status": "ok",
     "timestamp": 1611337114732,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "2Eq18R7WYXkD",
    "outputId": "9dca7040-b4d2-4de8-cb9b-c09decf6edf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Print the results\n",
    "visualize_images(result_images_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmsuPGWAbHvd"
   },
   "source": [
    "The modification has been done!<p>\n",
    "\n",
    "But as seen in the pictures, the colors are not kept constant along the images because tracking is not activated yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCEQikXa30Cx"
   },
   "source": [
    "# 2 - Association\n",
    "\n",
    "The next step is to match the detections from one frame to another frame and keep the color along the 9 images.<p>\n",
    "It should be dynamic and work regardless of the number of images. \n",
    "\n",
    "![Texte alternatif…](https://miro.medium.com/proxy/0*yN9MllhmuglJORss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-grOk3_hHSc"
   },
   "source": [
    "### IOU COST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 47236,
     "status": "ok",
     "timestamp": 1611337114733,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "0NpEcw8L5HnS"
   },
   "outputs": [],
   "source": [
    "def convert_data(box):\n",
    "    \"\"\"\n",
    "    Convert data from (x1,y1, w, h) to (x1,y1,x2,y2)\n",
    "    \"\"\"\n",
    "    x1 = box[0]\n",
    "    x2 = box[0] + box[2]\n",
    "    y1 = box[1]\n",
    "    y2 = box[1] + box[3]\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def box_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Computer Intersection Over Union cost\n",
    "    \"\"\"\n",
    "    box1 = convert_data(box1)\n",
    "    box2 = convert_data(box2)\n",
    "    xA = max(box1[0], box2[0])\n",
    "    yA = max(box1[1], box2[1])\n",
    "    xB = min(box1[2], box2[2])\n",
    "    yB = min(box1[3], box2[3])\n",
    "\n",
    "    inter_area = max(0, xB - xA + 1) * max(0, yB - yA + 1) # abs((xi2 - xi1)*(yi2 - yi1))\n",
    "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1) # abs((box1[3] - box1[1])*(box1[2]- box1[0]))\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1) # abs((box2[3] - box2[1])*(box2[2]- box2[0]))\n",
    "    union_area = (box1_area + box2_area) - inter_area\n",
    "    # compute the IoU\n",
    "    iou = inter_area/float(union_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRVXGejWhL_S"
   },
   "source": [
    "### Exponential, Linear, And IOU Costs\n",
    "\n",
    "[This paper](https://arxiv.org/pdf/1709.03572.pdf) is used for exponential, linear, and IOU costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 47233,
     "status": "ok",
     "timestamp": 1611337114734,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "OK7LfLBthi8r"
   },
   "outputs": [],
   "source": [
    "from math import sqrt, exp\n",
    "\n",
    "def check_division_by_0(value, epsilon = 0.01):\n",
    "  return (epsilon if value < epsilon else value)\n",
    "\n",
    "def hungarian_cost(old_box, new_box, iou_thresh = 0.3, linear_thresh = 10000, exp_thresh = 0.5):\n",
    "  w1 = 0.5\n",
    "  w2 = 1.5\n",
    "  (_, h, w, _) = np.array(dataset_images).shape\n",
    "  \n",
    "  # IOU_cost\n",
    "  iou_cost = box_iou(old_box, new_box)\n",
    "\n",
    "  # Sanchez-Matilla cost\n",
    "  Q_dist = sqrt(pow(w, 2) + pow(h, 2))\n",
    "  Q_shape = w * h\n",
    "  value = sqrt(pow(old_box[0] - new_box[0], 2) + pow(old_box[1] - new_box[1], 2))\n",
    "  value1 = sqrt(pow(old_box[2] - new_box[2], 2) + pow(old_box[3] - new_box[3], 2))\n",
    "  distance_term = Q_dist / check_division_by_0(value)\n",
    "  shape_term = Q_shape / check_division_by_0(value1)\n",
    "  linear_cost = distance_term * shape_term\n",
    "\n",
    "  # YUL cost\n",
    "  a = (old_box[0] - new_box[0]) / check_division_by_0(old_box[2]) ** 2\n",
    "  b = (old_box[1] - new_box[1]) / check_division_by_0(old_box[3]) ** 2\n",
    "  ab = -(a + b) * w1\n",
    "  c = abs(old_box[3] - new_box[3]) / (old_box[3] + new_box[3])\n",
    "  d = abs(old_box[2] - new_box[2]) / (old_box[2] + old_box[2])\n",
    "  cd = -(c + d) * w2\n",
    "  exp_cost = exp(ab) * exp(cd)\n",
    "  return (iou_cost if(iou_cost >= iou_thresh and linear_cost >= linear_thresh and exp_cost >= exp_thresh) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6CvRBXgjWK2"
   },
   "source": [
    "## The Hungarian Algorithm\n",
    "The previous for tracking is used here to track bounding boxes!\n",
    "\n",
    "The associate function takes two lists of boxes (time t-1 and time t) and outputs of it are the matches, the new detections, and the unmatched tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 47231,
     "status": "ok",
     "timestamp": 1611337114735,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "SXwhIsjd6kFY"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def associate(old_boxes, new_boxes):\n",
    "    \"\"\"\n",
    "    old_boxes represents the former bounding boxes (at time 0)\n",
    "    new_boxes represents the new bounding boxes (at time 1)\n",
    "    Function goal: Define a Hungarian Matrix with IOU as a metric and return, for each box, an id\n",
    "    RETURN: Matches, Unmatched Detections, Unmatched Trackers\n",
    "    \"\"\"\n",
    "    # Define a new IOU Matrix with old and new boxes\n",
    "    iou_matrix = np.zeros([len(old_boxes), len(new_boxes)], dtype = np.float32)\n",
    "\n",
    "    # Loop through boxes and store the IOU value for each box\n",
    "    for i, old_box in enumerate(old_boxes):\n",
    "      for j, new_box in enumerate(new_boxes):\n",
    "        iou_matrix[i][j] = hungarian_cost(old_box, new_box)\n",
    "\n",
    "    # Call for the hungarian algorithm\n",
    "    hungarian_row, hungarian_col = linear_sum_assignment(-iou_matrix)\n",
    "    hungarian_matrix = np.array(list(zip(hungarian_row, hungarian_col)))\n",
    "\n",
    "    # Create new unmatched lists for old and new boxes\n",
    "    matches, unmatched_detections, unmatched_trackers = [], [], []\n",
    "\n",
    "    # Loop through the  Hungarian matrix, if IOU of matched element is less than 0.3 then add to the unmatched list\n",
    "    for h in hungarian_matrix:\n",
    "      if(iou_matrix[h[0], h[1]] < 0.3):\n",
    "        unmatched_trackers.append(old_boxes[h[0]])\n",
    "        unmatched_detections.append(new_boxes[h[1]])\n",
    "      else:\n",
    "        matches.append(h.reshape(1, 2))\n",
    "\n",
    "    if(len(matches) == 0):\n",
    "      matches = np.empty((0, 2), dtype = int)\n",
    "    else:\n",
    "      matches = np.concatenate(matches, axis = 0)\n",
    "\n",
    "    # Loop through old_boxes, if there is not any matched detection then add it to unmatched_old_boxes\n",
    "    for t, trk in enumerate(old_boxes):\n",
    "      if(t not in hungarian_matrix[:, 0]):\n",
    "        unmatched_trackers.append(trk)\n",
    "\n",
    "    # Loop through new_boxes, if there is not any matched tracking then add it to unmatched_new_boxes\n",
    "    for d, det in enumerate(new_boxes):\n",
    "      if(d not in hungarian_matrix[:, 0]):\n",
    "        unmatched_detections.append(det)\n",
    "\n",
    "    return matches, unmatched_detections, unmatched_trackers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_TtyGCW5hvW"
   },
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 47228,
     "status": "ok",
     "timestamp": 1611337114735,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "m4uClkOsM7Mg"
   },
   "outputs": [],
   "source": [
    "def main(input_image):\n",
    "    \"\"\"\n",
    "    Receives an images\n",
    "    Outputs the result image, and a list of obstacle objects \n",
    "    \"\"\"\n",
    "    \n",
    "    global stored_obstacles # will be used to keep track of obstacles info\n",
    "    global idx # will be used to keep track of id info\n",
    "\n",
    "    # Run obstacle detection\n",
    "    image = copy.deepcopy(input_image)\n",
    "    _, out_boxes = yolo.inference(input_image)\n",
    "\n",
    "    # First iteration: find obstacles and draw rectangles\n",
    "    if(idx == 0):\n",
    "      stored_obstacles = []\n",
    "      for i, box in enumerate(out_boxes):\n",
    "        obs = Obstacle(idx, box)\n",
    "        left, top, right, bottom = convert_data(box) # Move to x1, x2, y1, y2\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), id_to_color(obs.idx), thickness = 10) # Draw the box on the image with id\n",
    "        image = cv2.putText(image, str(obs.idx), (left - 10, top - 10), cv2.FONT_HERSHEY_PLAIN, 1, id_to_color(obs.idx), thickness = 4)\n",
    "        stored_obstacles.append(obs) # Put every created obstacle in the final list\n",
    "        idx += 1\n",
    "      return image, stored_obstacles\n",
    "    elif(idx != 0): # In this case, we already have obstacles from the previous frame, Now it is time to association and connecting\n",
    "      # Before calling associate, a list of old obstacles should be created\n",
    "      old_obstacles = [obs.box for obs in stored_obstacles]\n",
    "      matches, unmatched_detections, unmatched_trackes = associate(old_obstacles, out_boxes) # Associate the obstacles\n",
    "      new_obstacles = []\n",
    "\n",
    "      # For every match, change the obstacle value\n",
    "      # Assign the id to the matched id\n",
    "      # Assign the box ot the new box\n",
    "\n",
    "      for match in matches:\n",
    "        obs = Obstacle(stored_obstacles[match[0]].idx, out_boxes[match[1]])\n",
    "        new_obstacles.append(obs)\n",
    "\n",
    "      # Loop through all unmatched detections and add these to obstacles\n",
    "      for new_obs in unmatched_detections:\n",
    "        idx += 1\n",
    "        obs = Obstacle(idx, new_obs)\n",
    "        new_obstacles.append(obs)\n",
    "\n",
    "      # For every obstacle, it is needed to draw on the image and return it\n",
    "      for i, obs in enumerate(new_obstacles):\n",
    "        left, top, right, bottom = convert_data(obs.box)\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), id_to_color(obs.idx), thickness = 10)\n",
    "        image = cv2.putText(image, str(obs.idx), (left - 10, top - 10), cv2.FONT_HERSHEY_PLAIN, 1, id_to_color(obs.idx), thickness = 4)\n",
    "      stored_obstacles = copy.deepcopy(new_obstacles)\n",
    "      return image, stored_obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "output_embedded_package_id": "1vyqbPC152phJKShfOVsrN8ANJeh8aaOI"
    },
    "executionInfo": {
     "elapsed": 59923,
     "status": "ok",
     "timestamp": 1611337127442,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "4cVeLR137YGf",
    "outputId": "284f3fa7-a830-49e4-b709-1ffb50ea592d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Call the main loop\n",
    "\n",
    "yolo = YOLO()\n",
    "idx = 0\n",
    "\n",
    "fig=plt.figure(figsize=(100,100))\n",
    "\n",
    "result_images_3 = copy.deepcopy(dataset_images)\n",
    "\n",
    "out_imgs = []\n",
    "\n",
    "for i in range(len(result_images_3)):\n",
    "    out_img, stored_obstacles = main(result_images_3[i])\n",
    "    out_imgs.append(out_img)\n",
    "    fig.add_subplot(1, len(result_images_3), i+1)\n",
    "    plt.imshow(out_imgs[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU0EM5o_LvAk"
   },
   "source": [
    "# 3 - Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRWklScdLr-7"
   },
   "source": [
    "### Using the Non Maxima Suppression formula\n",
    "\n",
    "In order to avoid results like below picture, NMS is going to be used:<p>\n",
    "![](https://user-images.githubusercontent.com/25801568/79720833-01a88180-82ea-11ea-993b-8accd6b7fcc1.png)\n",
    "\n",
    "A Non-Maxima Suppression formula is used based on this page [page](https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/).\n",
    "\n",
    "In order to do this, we have to change (x1, y1, w, h) to (x1, y1, x2, y2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125,
     "output_embedded_package_id": "1-Vof5ZsZN83dst64hmYEa7k0X4FzFMk3"
    },
    "executionInfo": {
     "elapsed": 73016,
     "status": "ok",
     "timestamp": 1611337140549,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "EZk4Lc1dLzFb",
    "outputId": "052a7d88-24f2-4568-cccf-54621998eeeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Tracking/Main\")\n",
    "from yolo_nms import *\n",
    "\n",
    "yolo = YOLO()\n",
    "idx = 0\n",
    "\n",
    "fig=plt.figure(figsize=(100,100))\n",
    "\n",
    "result_images_3 = copy.deepcopy(dataset_images)\n",
    "\n",
    "out_imgs = []\n",
    "\n",
    "for i in range(len(result_images_3)):\n",
    "    out_img, stored_obstacles = main(result_images_3[i])\n",
    "    out_imgs.append(out_img)\n",
    "    fig.add_subplot(1, len(result_images_3), i+1)\n",
    "    plt.imshow(out_imgs[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftb6lKOSBJup"
   },
   "source": [
    "### Using Age\n",
    "\n",
    "Currently, the tracker is working very good! <p>\n",
    "One thing that is not appropriate is that it relies solely on the detector.\n",
    "If we miss the detection, we miss everything. <p>\n",
    "Therefore, we need to add:\n",
    "* False Positive\n",
    "* False Negative<p>\n",
    "\n",
    "A **false positive** means that an pobstacle is detected an obstacle, which it should not be detected.<p>\n",
    "This can be solved by using a **MIN_HIT_STREAK** variable. If the detector detects something just for one time, it is not displayed. If it detects it more than once in a row, it is displayed.\n",
    "\n",
    "A **false negative** means that an obstacle is not detected, which it should be detected.<p>\n",
    "This can be solved by using a **MAX_AGE** variable. If an obstacle is suddently unmatched, we keep displaying it. If it is unmatched again for several times, it is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 73015,
     "status": "ok",
     "timestamp": 1611337140551,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "SvLcyXVrBgeq"
   },
   "outputs": [],
   "source": [
    "MIN_HIT_STREAK = 1\n",
    "MAX_UNMATCHED_AGE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeBeNMRWQHG8"
   },
   "source": [
    "**Obstacle Class** <p>\n",
    "Redefine the Obstacle class to include these values.\n",
    "Every obstacle should have:\n",
    "* an id\n",
    "* a box\n",
    "* an age (number of times matched)\n",
    "* an unmatched frame number (number of times unmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 73012,
     "status": "ok",
     "timestamp": 1611337140552,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "QyUG4St3QDTZ"
   },
   "outputs": [],
   "source": [
    "class Obstacle():\n",
    "    def __init__(self, idx, box, age = 1, unmatched_age = 0):\n",
    "        self.idx = idx\n",
    "        self.box = box\n",
    "        self.age = age\n",
    "        self.unmatched_age = unmatched_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 73009,
     "status": "ok",
     "timestamp": 1611337140553,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "l5UU7mgTQjR2"
   },
   "outputs": [],
   "source": [
    "def main(input_image):\n",
    "    \"\"\"\n",
    "    Receives an images\n",
    "    Outputs the result image, and a list of obstacle objects \n",
    "    \"\"\"\n",
    "    global stored_obstacles # Will be used to keep track of obstacles information\n",
    "    global idx # Will be used to keep track of id information\n",
    "    # Run obstacle detection\n",
    "    image = copy.deepcopy(input_image)\n",
    "    _, out_boxes = yolo.inference(input_image)\n",
    "    \n",
    "    # What we will do will be very similar but we have a second list of obstacles that answer to the conditions\n",
    "    # On first iteration, we only create obstacles with age=1\n",
    "    if (idx == 0):\n",
    "        stored_obstacles = []\n",
    "        for i, box in enumerate(out_boxes):\n",
    "            obs = Obstacle(idx, box) # Create an obstacle with age=1\n",
    "            stored_obstacles.append(obs)                \n",
    "            idx +=1\n",
    "        return image\n",
    "    \n",
    "    # On this case, if the obstacle has already been matched, we display it depending on the MIN_HIT_STREAK variable\n",
    "    elif (idx != 0): # In case we already have obstacles from previous frame, work on association\n",
    "        ## Before calling associate, we must create a list of old obstacles\n",
    "        old_obstacles = [obs.box for obs in stored_obstacles] # Simply get the boxes\n",
    "        matches, unmatched_detections, unmatched_tracks = associate(old_obstacles, out_boxes) # Associate the obstacles\n",
    "        \n",
    "        selected_obstacles = []\n",
    "        # Loop through all matches and add these as obstacles\n",
    "        new_obstacles = []\n",
    "        for match in matches:\n",
    "            obs = Obstacle(stored_obstacles[match[0]].idx, out_boxes[match[1]], stored_obstacles[match[0]].age +1) # Increase the age by 1\n",
    "            new_obstacles.append(obs)\n",
    "            if obs.age >= MIN_HIT_STREAK:\n",
    "                selected_obstacles.append(obs)\n",
    "        \n",
    "        # Loop through all unmatched detections and add these as obstacles\n",
    "        for new_obs in unmatched_detections:\n",
    "            idx +=1\n",
    "            obs = Obstacle(idx, new_obs)\n",
    "            new_obstacles.append(obs)\n",
    "            if obs.age >= MIN_HIT_STREAK:\n",
    "                selected_obstacles.append(obs)\n",
    "\n",
    "        for i, old_obs in enumerate(unmatched_tracks):\n",
    "            if stored_obstacles[i].box == old_obs:\n",
    "                obs = stored_obstacles[i] \n",
    "                obs.unmatched_age +=1\n",
    "                if obs.unmatched_age <= MAX_UNMATCHED_AGE:\n",
    "                    selected_obstacles.append(obs)\n",
    "\n",
    "        # Draw on selected obstacles only\n",
    "        for i, obs in enumerate(selected_obstacles):\n",
    "            left, top, right, bottom = convert_data(obs.box)\n",
    "            cv2.rectangle(image, (left, top), (right, bottom), id_to_color(obs.idx), thickness=10)\n",
    "            image = cv2.putText(image, str(obs.idx),(left,top),cv2.FONT_HERSHEY_SIMPLEX, 1,id_to_color(obs.idx),thickness=4)                \n",
    "\n",
    "        stored_obstacles = copy.deepcopy(new_obstacles)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210,
     "output_embedded_package_id": "1imwbL59TFMpWO3TKxHcbL4Hfi4zQgksN"
    },
    "executionInfo": {
     "elapsed": 85460,
     "status": "ok",
     "timestamp": 1611337153019,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "nE45f0_JQdGQ",
    "outputId": "00fadf05-da43-419a-ac7e-f1937858f333"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yolo = YOLO()\n",
    "idx = 0\n",
    "\n",
    "fig=plt.figure(figsize=(100,100))\n",
    "\n",
    "result_images_3 = copy.deepcopy(dataset_images)\n",
    "\n",
    "out_imgs = []\n",
    "\n",
    "for i in range(len(result_images_3)):\n",
    "    out_img = main(result_images_3[i])\n",
    "    out_imgs.append(out_img)\n",
    "    fig.add_subplot(1, len(result_images_3), i+1)\n",
    "    plt.imshow(out_imgs[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NENpEO4iHbOX"
   },
   "source": [
    "# 4 - Kalman Filter\r\n",
    "\r\n",
    "Now, It is time to introduce Kalman Filter to this project. Kalman Filters will help predict the future position of a bounding box, so that the association will always match in the future.\r\n",
    "\r\n",
    "state of the Kalman Filter consistes of 4 variables: x, y, w, h. <p>\r\n",
    "These are the values returned by the YOLO algorithm.\r\n",
    "\r\n",
    "The process will be the following\r\n",
    "*   Detect bounding boxes\r\n",
    "*   Associate it with the previous predictions\r\n",
    "*   Predict the next position of each box\r\n",
    "<p>\r\n",
    "The association is made with the prediction from t-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223415,
     "status": "ok",
     "timestamp": 1611337290992,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "owojLdxtIK4-",
    "outputId": "fd3718bd-66a9-458b-b279-d2c8a27471d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting filterpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/ac8914360460fafa1990890259b7fa5ef7ba4cd59014e782e4ab3ab144d8/filterpy-1.4.5.zip (177kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 16.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from filterpy) (3.2.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->filterpy) (1.15.0)\n",
      "Building wheels for collected packages: filterpy\n",
      "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for filterpy: filename=filterpy-1.4.5-cp36-none-any.whl size=110453 sha256=3b5737a4f10a1c58b3a8f66480225ceae188ec853140c7f2930993c13f5dc56d\n",
      "  Stored in directory: /root/.cache/pip/wheels/c3/0c/dd/e92392c3f38a41371602d99fc77d6c1d42aadbf0c6afccdd02\n",
      "Successfully built filterpy\n",
      "Installing collected packages: filterpy\n",
      "Successfully installed filterpy-1.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 223743,
     "status": "ok",
     "timestamp": 1611337291325,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "XtMdoYR1IO74"
   },
   "outputs": [],
   "source": [
    "from filterpy.kalman import KalmanFilter\r\n",
    "from scipy.linalg import block_diag\r\n",
    "from filterpy.common import Q_discrete_white_noise\r\n",
    "import time\r\n",
    "\r\n",
    "def FourDimensionsKF(R_std = 10, Q_std = 0.01):\r\n",
    "    kf = KalmanFilter(dim_x = 8, dim_z = 4)\r\n",
    "    kf.F = np.array([[1, 1, 0, 0, 0, 0, 0, 0],\r\n",
    "                     [0, 1, 0, 0, 0, 0, 0, 0],\r\n",
    "                     [0, 0, 1, 1, 0, 0, 0, 0],\r\n",
    "                     [0, 0, 0, 1, 0, 0, 0, 0],\r\n",
    "                     [0, 0, 0, 0, 1, 1, 0, 0],\r\n",
    "                     [0, 0, 0, 0, 0, 1, 0, 0],\r\n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1],\r\n",
    "                     [0, 0, 0, 0, 0, 0, 0, 1]])\r\n",
    "\r\n",
    "    kf.P *= 1000\r\n",
    "    kf.R[2:, 2:] *= R_std\r\n",
    "    kf.Q[-1, -1] *= Q_std\r\n",
    "    kf.Q[4:, 4:] *= Q_std\r\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 223742,
     "status": "ok",
     "timestamp": 1611337291326,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "Q9XUSuB1Ijwl"
   },
   "outputs": [],
   "source": [
    "class Obstacle():\r\n",
    "    def __init__(self, idx, box, time, age = 1, unmatched_age = 0):\r\n",
    "        self.idx = idx\r\n",
    "        self.box = box\r\n",
    "        self.age = age\r\n",
    "        self.unmatched_age = unmatched_age\r\n",
    "        self.time = time\r\n",
    "        self.kf = FourDimensionsKF()\r\n",
    "        self.kf.x = np.array([box[0], 0, box[1], 0, box[2], 0, box[3], 0])\r\n",
    "        self.kf.H = np.array([[1, 0, 0, 0, 0, 0, 0, 0],\r\n",
    "                             [0, 0, 1, 0, 0, 0, 0, 0],\r\n",
    "                             [0, 0, 0, 0, 1, 0, 0, 0],\r\n",
    "                             [0, 0, 0, 0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 223740,
     "status": "ok",
     "timestamp": 1611337291327,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "FbIMPD5NIvHF"
   },
   "outputs": [],
   "source": [
    "def get_obs_from_mean(mean):\r\n",
    "    return [mean[0], mean[2], mean[4], mean[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 223737,
     "status": "ok",
     "timestamp": 1611337291327,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "TdzNkCCzIzNC"
   },
   "outputs": [],
   "source": [
    "def return_F_with_dt(dt):\r\n",
    "    dt = 1./25. #VIDEO MODE\r\n",
    "    F = np.array([[1,dt, 0,  0, 0, 0, 0, 0],\r\n",
    "                  [0, 1, 0,  0, 0, 0, 0, 0],\r\n",
    "                  [0, 0, 1, dt, 0, 0, 0, 0],\r\n",
    "                  [0, 0, 0,  1, 0, 0, 0, 0],\r\n",
    "                  [0, 0, 0, 0, 1, dt, 0, 0],\r\n",
    "                  [0, 0, 0, 0, 0,  1, 0, 0],\r\n",
    "                  [0, 0, 0, 0, 0, 0, 1, dt],\r\n",
    "                  [0, 0, 0, 0, 0, 0, 0,  1]])\r\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 223736,
     "status": "ok",
     "timestamp": 1611337291328,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "UZKmlG4QJFSz"
   },
   "outputs": [],
   "source": [
    "def main(input_image):\r\n",
    "    \"\"\"\r\n",
    "    Receives an images\r\n",
    "    Outputs the result image, and a list of obstacle objects \r\n",
    "    \"\"\"\r\n",
    "    global stored_obstacles\r\n",
    "    global idx\r\n",
    "    global yolo\r\n",
    "    \r\n",
    "    image = copy.deepcopy(input_image)\r\n",
    "    _, out_boxes = yolo.inference(input_image)\r\n",
    "    current_time = time.time()\r\n",
    "    \r\n",
    "    # First Detection, Initialize a Kalman Filter per Bounding Box\r\n",
    "    if (idx == 0):\r\n",
    "        stored_obstacles = []\r\n",
    "        for i, box in enumerate(out_boxes):\r\n",
    "            obs = Obstacle(idx, box, current_time)\r\n",
    "            stored_obstacles.append(obs)\r\n",
    "            idx +=1\r\n",
    "        return input_image\r\n",
    "    \r\n",
    "    # Not First Detection\r\n",
    "    elif (idx != 0):                \r\n",
    "        # Match between old obstacles and new using Hungarian Algorithm\r\n",
    "        old_boxes = [obs.box for obs in stored_obstacles]\r\n",
    "        matches, unmatched_detections, unmatched_tracks = associate(old_boxes, out_boxes)\r\n",
    "\r\n",
    "        selected_obstacles = []\r\n",
    "        new_obstacles = []\r\n",
    "\r\n",
    "        # For Matched Obstacles, Update & Predict the next position; store in Box for future match\r\n",
    "        for match in matches:\r\n",
    "            obs = stored_obstacles[match[0]] # Take the former obstacle and its ID\r\n",
    "            obs.age += 1 # Increment the age by 1\r\n",
    "            \r\n",
    "            # Update\r\n",
    "            measurement = out_boxes[match[1]]         \r\n",
    "            obs.kf.update(np.array(measurement))\r\n",
    "\r\n",
    "            # Prediction\r\n",
    "            F = return_F_with_dt(current_time - obs.time)\r\n",
    "            obs.kf.F = F\r\n",
    "            obs.kf.predict()\r\n",
    "            obs.time = current_time\r\n",
    "            obs.box = get_obs_from_mean(obs.kf.x)\r\n",
    "            \r\n",
    "            new_obstacles.append(obs)\r\n",
    "            if obs.age >= MIN_HIT_STREAK:\r\n",
    "                selected_obstacles.append(obs)\r\n",
    "\r\n",
    "        # For Unmatched Detections, the same as idx = 0\r\n",
    "        for new_obs in unmatched_detections:\r\n",
    "            idx += 1\r\n",
    "            obs = Obstacle(idx, new_obs, current_time)\r\n",
    "            new_obstacles.append(obs)\r\n",
    "            if obs.age >= MIN_HIT_STREAK:\r\n",
    "                selected_obstacles.append(obs)\r\n",
    "\r\n",
    "        # For Unmatched Tracks, Predict using dt\r\n",
    "        for i, old_obs in enumerate(unmatched_tracks):\r\n",
    "            if stored_obstacles[i].box == old_obs:\r\n",
    "                obs = stored_obstacles[i]\r\n",
    "                F = return_F_with_dt(current_time - obs.time)\r\n",
    "                obs.time = current_time\r\n",
    "                obs.kf.F = F\r\n",
    "                obs.kf.predict()\r\n",
    "                obs.box = get_obs_from_mean(obs.kf.x)\r\n",
    "                obs.unmatched_age += 1\r\n",
    "                if obs.unmatched_age <= MAX_UNMATCHED_AGE:\r\n",
    "                    selected_obstacles.append(obs)\r\n",
    "\r\n",
    "        # Draw on selected obstacles only\r\n",
    "        for i, obs in enumerate(selected_obstacles):\r\n",
    "            left, top, right, bottom = convert_data(obs.box)\r\n",
    "            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), id_to_color(obs.idx), thickness = 10)\r\n",
    "            image = cv2.putText(image, str(obs.idx),(int(left),int(top)),cv2.FONT_HERSHEY_SIMPLEX, 1,id_to_color(obs.idx),thickness = 4)                \r\n",
    "        stored_obstacles = copy.deepcopy(new_obstacles)\r\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210,
     "output_embedded_package_id": "1iIrnY5AQUwSUVWM0zviv9Hx3rx6A9uGz"
    },
    "executionInfo": {
     "elapsed": 239035,
     "status": "ok",
     "timestamp": 1611337306630,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "qmmLEI7NJsgM",
    "outputId": "0a645dde-7cee-4330-81b2-58afdaffb3fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yolo = YOLO()\r\n",
    "\r\n",
    "idx = 0\r\n",
    "\r\n",
    "fig=plt.figure(figsize=(100,100))\r\n",
    "\r\n",
    "result_images_3 = copy.deepcopy(dataset_images)\r\n",
    "\r\n",
    "out_imgs = []\r\n",
    "\r\n",
    "for i in range(len(result_images_3)):\r\n",
    "    out_img = main(result_images_3[i])\r\n",
    "    out_imgs.append(out_img)\r\n",
    "    fig.add_subplot(1, len(result_images_3), i + 1)\r\n",
    "    plt.imshow(out_imgs[i])\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjWYX1uEJz8b"
   },
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375058,
     "status": "ok",
     "timestamp": 1611337442655,
     "user": {
      "displayName": "Arash Ahangarnejad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPOccHaF02b_GF2YpqsZFzW9qZwcYa5Od-3DQZ7w=s64",
      "userId": "07365192062957088470"
     },
     "user_tz": 300
    },
    "id": "nVrES7xxJ1_6",
    "outputId": "7b79abd1-2c5a-4035-bc27-001ce1f9f9ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /content/drive/My Drive/Colab Notebooks/Tracking/Main/Images/movie_track_kf_out.mp4\n",
      "[MoviePy] Writing video /content/drive/My Drive/Colab Notebooks/Tracking/Main/Images/movie_track_kf_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 125/126 [02:15<00:01,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /content/drive/My Drive/Colab Notebooks/Tracking/Main/Images/movie_track_kf_out.mp4 \n",
      "\n",
      "CPU times: user 3min 58s, sys: 8.16 s, total: 4min 7s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\r\n",
    "idx = 0\r\n",
    "detector = YOLO()\r\n",
    "video_file = \"/content/drive/My Drive/Colab Notebooks/Tracking/Main/Images/MOT16-14-raw.mp4\" #25 FPS\r\n",
    "clip = VideoFileClip(video_file).subclip(0,5)\r\n",
    "white_clip = clip.fl_image(main)\r\n",
    "%time white_clip.write_videofile(\"/content/drive/My Drive/Colab Notebooks/Tracking/Main/Images/movie_track_kf_out.mp4\",audio=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of final_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
